{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inspire-lab/CyberAI-labs/blob/main/category-PrivateAI/CNN-inference-homomorphic-encryption/Encrypted_Convolution_on_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encrypted Convolution on MNIST\n",
        "\n",
        "Here we are going to perform encrypted evaluation on MNIST examples, using a convolutional neural network (CNN).\n",
        "\n",
        "We will be using CKKS extensively in this lab same as in previous lab.\n",
        "\n",
        "We will start by explaining how the different layers can be performed on encrypted data. Next we train a PyTorch model on MNIST, then implement an equivalent one using TenSEAL, but which can evaluate encrypted inputs."
      ],
      "metadata": {
        "id": "vXs5Z2l_lhPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning Model\n",
        "\n",
        "With the MNIST dataset in hand, we can use a simple neural network composed of a convolutional layer, followed by two linear layers. Here we use the square activation function for simplicity, and ease of use, given the limitation of the number of multiplications with the CKKS scheme.\n",
        "\n",
        "We will keep in mind that the input for the model needs to be encrypted using CKKS, but the parameters of the model don't, they will be kept in plain during the whole protocol.\n",
        "\n",
        "### Model Description\n",
        "The model is the sequence of the below layers:\n",
        "\n",
        "- **Conv:** Convolution with 4 kernels. Shape of the kernel is 7x7. Strides are 3x3.\n",
        "- **Activation:** Square activation function.\n",
        "- **Linear Layer 1:** Input size: 256. Output size: 64.\n",
        "- **Activation:** Square activation function.\n",
        "- **Linear Layer 2:** Input size: 64. Output size: 10.\n",
        "\n",
        "\n",
        "### Input Representation\n",
        "\n",
        "In order to keep the memory and computation to its lowest, we will mostly try to use a single ciphertext. It's not always possible, and we often loose some flexibility. For this model, there are two different representations. One for the convolution, and one for the linear layers. The former will be quickly explained in the convolution section. For the latter, it's simply the input vector for the linear layer which is replicated many times to fit the slots of the ciphertexts. So a single ciphertext will contain the whole input for the linear layer.\n",
        "\n",
        "\n",
        "### Convolution\n",
        "\n",
        "There is actually different ways for doing convolution, and one way we can do it is via a well-known algorithm that translates the 2D convolution into a single matrix multiplication operation. This operation is often referred to as image-to-column convolution and is depicted in *Figure1*.\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://github.com/OpenMined/TenSEAL/blob/main/tutorials/assets/im2col_conv2d.png?raw=true\" width=\"50%\"/>\n",
        "<div><b>Figure1:</b> Image to column convolution</div>\n",
        "</div>\n",
        "\n",
        "However, this requires arranging the elements of the input matrix in a special way, and since we can't easily do that with a ciphertext, we have to do this as a pre-processing step before encryption. This also means that only a single convolution can be performed. To perform the convolution, we first need to do *im2col* encoding to the input matrix and encrypt it into a single ciphertext. It's worth noting that the matrix is translated into a vector using vertical scan. We then perform a matrix multiplication between an encrypted matrix (input image encoded in a ciphertext) and a plain vector (the flattened kernel of the convolution). This is done by first constructing this new flattened kernel, which replicates every element in the kernel $n$ times, where $n$ is the number of windows. Then we perform a ciphertext-plaintext multiplication, and continue with a sequence of rotate and sum operations in order to sum the elements of the same window. The process is depicted in *Figure 2* and *Figure 3*.\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://github.com/OpenMined/TenSEAL/blob/main/tutorials/assets/im2col_conv2d_ckks1.png?raw=true\" width=\"50%\"/>\n",
        "<div><b>Figure2:</b> Image to column convolution with CKKS - step 1</div>\n",
        "</div>\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://github.com/OpenMined/TenSEAL/blob/main/tutorials/assets/im2col_conv2d_ckks2.png?raw=true\" width=\"50%\"/>\n",
        "<div><b>Figure3:</b> Image to column convolution with CKKS - step 2</div>\n",
        "</div>\n",
        "\n",
        "If multiple kernels are used, then we need to perform this operation multiple times, yielding different output ciphertexts. These ciphertexts can later be combined (using a single multiplication) into a flattened vector. So every convolution will output a ciphertext containing 64 useful slots, then combining the 4 kernel outputs will yield us a ciphertext with 256 useful slots that will be the input for the first linear layer. The algorithm requires a single multiplication and $log_2(n)$ ciphertext rotations where $n$ is the number of windows in the convolution.\n",
        "\n",
        "### Linear Layer\n",
        "A linear layer boils down to a vector-matrix multiplication and an addition of a bias. The matrix and the bias are not encrypted. The vector-matrix multiplication is implemented based on [Halevi and Shoup ](https://link.springer.com/chapter/10.1007/978-3-662-44371-2_31) diagonal method. It's an accumulation of multiple ciphertext-plaintext multiplications, with slightly different rotations. We iterate over every diagonal in the plain matrix and multiply it with the ciphertext rotated $n$ slots to the left, where $n$ is the index (0-indexed) of the diagonal. The process is depicted in *Figure 4*. The algorithm runs in $O(n)$ where $n$ is the size of the encrypted vector.\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://github.com/OpenMined/TenSEAL/blob/main/tutorials/assets/vec-matmul.png?raw=true\" width=\"65%\"/>\n",
        "<div><b>Figure4:</b> Vector-Matrix Multiplication</div>\n",
        "</div>\n",
        "\n",
        "### Square Activation\n",
        "The square activation is pretty straightforward. We just multiply a ciphertext by itself.\n",
        "\n",
        "\n",
        "Building on these operations, we now know that this evaluation requires exactly 6 multiplications to be performed, 2 for the convolution, 1 for the first square activation, 1 for the first linear layer, 1 for the second square activation, and finally 1 for the last linear layer."
      ],
      "metadata": {
        "id": "ZQJqImTalhPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Now that we know how we can implement such a model via HE, we will start using a library called [TenSEAL](https://github.com/OpenMined/TenSEAL) that implements all these operations we have been describing. But first, we need to train a plain PyTorch model to classify the MNIST dataset."
      ],
      "metadata": {
        "id": "BfI1yywOlhPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets  # Import datasets from torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_data = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
        "test_data = Subset(test_data,np.arange(100))"
      ],
      "metadata": {
        "id": "OhbmoeWmIKXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e2f4629-ad2c-43cb-8424-c6bee15e7262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 30.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.14MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 9.63MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.38MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N4Jpj17KyVg",
        "outputId": "7a17f516-2521-454d-f721-a11a9f587f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(73)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=64, output=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n",
        "        self.fc1 = torch.nn.Linear(256, hidden)\n",
        "        self.fc2 = torch.nn.Linear(hidden, output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        # the model uses the square activation function\n",
        "        x = x * x\n",
        "        # flattening while keeping the batch axis\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc1(x)\n",
        "        x = x * x\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, n_epochs=10):\n",
        "    # model in training mode\n",
        "    model.train()\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "\n",
        "        train_loss = 0.0\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # calculate average losses\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
        "\n",
        "    # model in evaluation mode\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "model = ConvNet()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "model = train(model, train_loader, criterion, optimizer, 10)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.397561\n",
            "Epoch: 2 \tTraining Loss: 0.130699\n",
            "Epoch: 3 \tTraining Loss: 0.088399\n",
            "Epoch: 4 \tTraining Loss: 0.071318\n",
            "Epoch: 5 \tTraining Loss: 0.058989\n",
            "Epoch: 6 \tTraining Loss: 0.050542\n",
            "Epoch: 7 \tTraining Loss: 0.044438\n",
            "Epoch: 8 \tTraining Loss: 0.038261\n",
            "Epoch: 9 \tTraining Loss: 0.034641\n",
            "Epoch: 10 \tTraining Loss: 0.030696\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_e2ctjUlhPK",
        "outputId": "40d6f65f-bd59-42d5-e007-b90b8727ef2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then test its accuracy on the test set:"
      ],
      "metadata": {
        "id": "h6LMrApHlhPL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def test(model, test_loader, criterion):\n",
        "    # initialize lists to monitor test loss and accuracy\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "\n",
        "    # model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        for i in range(len(target)):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss/len(test_loader)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )\n",
        "\n",
        "test(model, test_loader, criterion)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.006644\n",
            "\n",
            "Test Accuracy of 0: 100% (8/8)\n",
            "Test Accuracy of 1: 100% (14/14)\n",
            "Test Accuracy of 2: 100% (8/8)\n",
            "Test Accuracy of 3: 100% (11/11)\n",
            "Test Accuracy of 4: 100% (14/14)\n",
            "Test Accuracy of 5: 100% (7/7)\n",
            "Test Accuracy of 6: 100% (10/10)\n",
            "Test Accuracy of 7: 100% (15/15)\n",
            "Test Accuracy of 8: 100% (2/2)\n",
            "Test Accuracy of 9: 100% (11/11)\n",
            "\n",
            "Test Accuracy (Overall): 100% (100/100)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5Ga8RRrlhPL",
        "outputId": "76fc170b-3db0-4e18-8866-f3f46cff0d3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tenseal==0.3.15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOrMlbJsnEvN",
        "outputId": "9ae4cc0b-d301-4d77-879d-73b7d05e8970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tenseal==0.3.15\n",
            "  Downloading tenseal-0.3.15-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.2 kB)\n",
            "Downloading tenseal-0.3.15-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/4.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/4.8 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenseal\n",
            "Successfully installed tenseal-0.3.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encrypted Evaluation\n",
        "\n",
        "Now start the encrypted evaluation that will use the pre-trained model:"
      ],
      "metadata": {
        "id": "MIoUu0iBlhPL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"\n",
        "It's a PyTorch-like model using operations implemented in TenSEAL.\n",
        "    - .mm() method is doing the vector-matrix multiplication explained above.\n",
        "    - you can use + operator to add a plain vector as a bias.\n",
        "    - .conv2d_im2col() method is doing a single convlution operation.\n",
        "    - .square_() just square the encrypted vector inplace.\n",
        "\"\"\"\n",
        "\n",
        "import tenseal as ts\n",
        "\n",
        "\n",
        "class EncConvNet:\n",
        "    def __init__(self, torch_nn):\n",
        "        self.conv1_weight = torch_nn.conv1.weight.data.view(\n",
        "            torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],\n",
        "            torch_nn.conv1.kernel_size[1]\n",
        "        ).tolist()\n",
        "        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n",
        "\n",
        "        self.fc1_weight = torch_nn.fc1.weight.T.data.tolist()\n",
        "        self.fc1_bias = torch_nn.fc1.bias.data.tolist()\n",
        "\n",
        "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
        "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
        "\n",
        "\n",
        "    def forward(self, enc_x, windows_nb):\n",
        "        # conv layer\n",
        "        enc_channels = []\n",
        "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
        "            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias\n",
        "            enc_channels.append(y)\n",
        "        # pack all channels into a single flattened vector\n",
        "        enc_x =\n",
        "        #####################\n",
        "        #Your code goes here\n",
        "        #####################\n",
        "        # square activation\n",
        "        #####################\n",
        "        #Your code goes here\n",
        "        #####################\n",
        "        # fc1 layer\n",
        "        enc_x = enc_x.mm(self.fc1_weight) + self.fc1_bias\n",
        "        # square activation\n",
        "        enc_x.square_()\n",
        "        # fc2 layer\n",
        "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
        "        return enc_x\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "\n",
        "def enc_test(context, model, test_loader, criterion, kernel_shape, stride):\n",
        "    # initialize lists to monitor test loss and accuracy\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        # Encoding and encryption\n",
        "        x_enc, windows_nb = ts.im2col_encoding(\n",
        "            context, data.view(28, 28).tolist(), kernel_shape[0],\n",
        "            kernel_shape[1], stride\n",
        "        )\n",
        "        # Encrypted evaluation\n",
        "        enc_output = enc_model(x_enc, windows_nb)\n",
        "        # Decryption of result\n",
        "        output =\n",
        "        #####################\n",
        "        #Your code goes here\n",
        "        #####################\n",
        "        output = torch.tensor(output).view(1, -1)\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        label = target.data[0]\n",
        "        class_correct[label] += correct.item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss / sum(class_total)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )\n",
        "\n",
        "\n",
        "# Load one element at a time\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "# required for encoding\n",
        "kernel_shape = model.conv1.kernel_size\n",
        "stride = model.conv1.stride[0]"
      ],
      "outputs": [],
      "metadata": {
        "id": "NF3-fiyUlhPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing the parameters isn't easy, so we list some intuition here for why we have chosen these parameters exactly:\n",
        "\n",
        "1. For a given security level (e.g. 128-bits security) and a polynomial modulus degree (e.g. 8192) there is an upper bound for the bit count of the coefficient modulus (`sum(coeff_mod_bit_sizes)`). If the upper bound is surpassed, there is a need to use a higher polynomial modulus degree (e.g. 16384) in order to make sure we still have the required security level.\n",
        "2. The multiplicative depth is controlled by the number of primes constituting our coefficient modulus.\n",
        "3. All elements of `coeff_mod_bit_sizes[1: -1]` should be equal in TenSEAL, since it takes care of rescaling ciphertexts. And we also want to use the same number of bits (e.g. 2 ^ 26) for the scale during encryption.\n",
        "4. The scale is what controls the precision of the fractional part, since it's the value that plaintexts are multiplied with before being encoded into a polynomial of integer coefficients.\n",
        "\n",
        "Starting with a scale of more than 20 bits, we need to choose the number of bits of all the middle primes equal to that, so we are already over 120 bits. With this lower bound of coefficient modulus and a security level of 128-bits, we will need a polynomial modulus degree of at least 8192. The upper bound for choosing a higher degree is at 218. Trying different values for the precision and adjusting the coefficient modulus, while studying the loss and accuracy, we end up with 26-bits of scale and primes. We also have 5 bits (31 - 26) for the integer part in the last coefficient modulus, which should be enough for our use case, since output values aren't that big."
      ],
      "metadata": {
        "id": "0UPF344elhPM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## Encryption Parameters\n",
        "\n",
        "# controls precision of the fractional part\n",
        "bits_scale = 26\n",
        "\n",
        "# Create TenSEAL context\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=8192,\n",
        "    coeff_mod_bit_sizes=[31, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 31]\n",
        ")\n",
        "\n",
        "# set the scale\n",
        "context.global_scale = pow(2, bits_scale)\n",
        "\n",
        "# galois keys are required to do ciphertext rotations\n",
        "context.generate_galois_keys()"
      ],
      "outputs": [],
      "metadata": {
        "id": "bCeWF9CKlhPM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "enc_model = EncConvNet(model)\n",
        "enc_test(context, enc_model, test_loader, criterion, kernel_shape, stride)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.008425\n",
            "\n",
            "Test Accuracy of 0: 100% (8/8)\n",
            "Test Accuracy of 1: 100% (14/14)\n",
            "Test Accuracy of 2: 100% (8/8)\n",
            "Test Accuracy of 3: 100% (11/11)\n",
            "Test Accuracy of 4: 100% (14/14)\n",
            "Test Accuracy of 5: 100% (7/7)\n",
            "Test Accuracy of 6: 100% (10/10)\n",
            "Test Accuracy of 7: 100% (15/15)\n",
            "Test Accuracy of 8: 100% (2/2)\n",
            "Test Accuracy of 9: 100% (11/11)\n",
            "\n",
            "Test Accuracy (Overall): 100% (100/100)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kz5YN5DlhPN",
        "outputId": "0379806f-893d-4f5f-9dc6-d2559850c5e6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "https://github.com/OpenMined/TenSEAL"
      ],
      "metadata": {
        "id": "8xJu8ssVpOva"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}