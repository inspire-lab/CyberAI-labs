{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inspire-lab/CyberAI-labs/blob/main/category-AIforCyber/Encrypted-traffic-analysis/encrypted_traffic_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MJlmq5RNfup"
      },
      "source": [
        "## Why is unencrypted network traffic dangerous?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6DufhBPjePP"
      },
      "source": [
        "Malwares can intercept and read users' data such as their credit card information and password authentication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-wTN7xEjePQ"
      },
      "source": [
        "## Why is encrypted network traffic better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWH7dgWcjePQ"
      },
      "source": [
        "Encrypted network traffic can protect security and privacy, especially the man-in-the-middle attack."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH3GqPPOjePQ"
      },
      "source": [
        "## What is SSL, TLS and HTTPS?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG1W0-3NjePQ"
      },
      "source": [
        "SSL (Security Socket Layer) is the standard technology for keeping an internet connection secure and safeguarding any sentitive data that is being sent between two systems, preventing criminals from reading and modifying any information transferred, including potential personal details. The two systems can be a server and a client (for example, a shopping website and browser) or server to server (for example, an application with personal identifiable information or with payroll informaiton)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKjR1_kujePQ"
      },
      "source": [
        "It does this by making sure that any data transferred between users and sites, or between two systems remains impossible to read. It uses encryption algorithms to secure data in transit, perventing hackers from reading it as it is sent over the connection. This information should be anything sensitive or personal which can include creadit card and other financial information, names and addresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7GfTIOqjePR"
      },
      "source": [
        "TLS (Transport Layer Security) is just an updated, more secure version of SSL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvSOGZBcjePR"
      },
      "source": [
        "HTTPS (Hyper Text Transfer Protocol Secure) appears in the URL when a website is secured by an SSL certificate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWFjo1D0jePR"
      },
      "source": [
        "## What is the problem of encrypted network traffic?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GEo5YC7jePS"
      },
      "source": [
        "It is hard to distinguish between benign and malicious behaviors since attackers hide malicious activities in encrypted traffic to avoid internet monitoring tool, that is, pretend to be normal TLS or SSL traffic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDU3CDtgjePS"
      },
      "source": [
        "## What are the ways to encrypt threats?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MouElauajePS"
      },
      "source": [
        "Attackers have many ways to hide threats via encryption. C2 or C&C, which means command and control, consist of communications between malwares and attackers. Backdoor attack is a type of malwares that used to get unauthorized access to a website by spreading them in the system through unsecured points of entry (backdoor), such as outdated plug-ins or input fields."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btSc0ghIjePS"
      },
      "source": [
        "data breach， botnet， RAT， banking trojans, ransomware, crypto-currency mining (without users' authentication)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amYHzJqWjePT"
      },
      "source": [
        "## How to detect malware attack behavior?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLW1q4vTjePT"
      },
      "source": [
        "The traditional way to detect malware attack behavior is directly decrypte the encrypted traffic. However, this way can has damage to privacy and results in high cost. Thus, the Cisco team introduced ETA (encrypted traffic analysis), which can get high accuracy without decryption."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDbog0w1jePT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf2\n",
        "import tensorflow.compat.v1 as tf\n",
        "#tf.disable_v2_behavior()\n",
        "\n",
        "import os\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from tabulate import tabulate\n",
        "import random\n",
        "\n",
        "# Disable eager execution for TensorFlow 1.x style\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "config = tf.compat.v1.ConfigProto(log_device_placement=True)\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.Session(config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDu7EqEykDiP"
      },
      "source": [
        "#Question 1\n",
        "\n",
        "##Next, we're going to consider a set of inputs\n",
        "Add in the directory of your source data files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TyPkC_8jyfm"
      },
      "outputs": [],
      "source": [
        "\n",
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################\n",
        "\n",
        "# Convert patience to int for comparisons\n",
        "patience = int(opts['patience'])\n",
        "\n",
        "FOLDER = opts['output_path']\n",
        "MODEL_PATH = FOLDER + '/model.ckpt'\n",
        "FIG_PATH = FOLDER + '/Confusion_Matrix.png'\n",
        "FIG_PATH_N = FOLDER + '/Confusion_Matrix_Norm.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awk1Tdf6wX_Y"
      },
      "source": [
        "##Next, we're going to define the layers of neurons. Each one has a different value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE2lqwVprSx1"
      },
      "outputs": [],
      "source": [
        "n_hidden_1 = 1280\n",
        "n_hidden_2 = 960\n",
        "n_hidden_3 = 640\n",
        "n_hidden_4 = 640\n",
        "n_hidden_5 = 480\n",
        "n_hidden_6 = 320\n",
        "n_hidden_7 = 320\n",
        "num_input = 886"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvBW_5jUwl9b"
      },
      "source": [
        "#Question 2\n",
        "\n",
        "\n",
        "##We have 12 classes in total.\n",
        "\n",
        "As you can see, we have a dictionary with the key as the class name and the value as its numerical ID.\n",
        "\n",
        "Now try to create a dictionary with the opposite - keys as the numerical ID and values as the class name - from the previously created dictionary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMOILuKrwlV1"
      },
      "outputs": [],
      "source": [
        "LABEL2DIG = {\n",
        "    'chat':0, 'voip':1, 'trap2p':2, 'stream':3, 'file_trans':4, 'email':5,\n",
        "    'vpn_chat':6, 'vpn_voip':7, 'vpn_trap2p':8, 'vpn_stream':9, 'vpn_file_trans':10, 'vpn_email':11\n",
        "}\n",
        "\n",
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################\n",
        "\n",
        "\n",
        "nclass = 12\n",
        "\n",
        "np.random.seed(0)\n",
        "tf.compat.v1.set_random_seed(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCjrJw3Bxrd2"
      },
      "source": [
        "#Question 3\n",
        "\n",
        "##Now load the X_train and y_train numpy files that have been stored in your source folder.\n",
        "\n",
        "Additionally, print out the size/shape of the data to be trained upon. Print out the distribution of each class in the training dataset.\n",
        "\n",
        "Try to create a list containing the class weights. This will be used later in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr47qDU6xoOT"
      },
      "outputs": [],
      "source": [
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P-wFgB4yHTp"
      },
      "source": [
        "#Question 4\n",
        "##Attempt to split the data into train and test sets. Use a split of 15% for the test data\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDNngU0Sl3ru"
      },
      "outputs": [],
      "source": [
        "clw = [i*maxsize for i in clw]\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = y_train\n",
        "y_train = to_categorical(y_train, num_classes = nclass)\n",
        "X_train = normalize(X_train, norm='max', axis=0, copy=True, return_norm=False)\n",
        "\n",
        "\n",
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################\n",
        "\n",
        "\n",
        "\n",
        "print(\"Dimensions: \",dim)\n",
        "size = np.shape(X_train)[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnAulOWGuqyZ"
      },
      "source": [
        "#Question 5\n",
        "\n",
        "##Predict a Random Class\n",
        "\n",
        "To set a baseline, add a model that predicts a random class for the test data.\n",
        "\n",
        "Then, calculate and print the F1-score, Precision, and Recall in the form of a table. Finally, print the Macro F1-score across all of the classes as well.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xsxS55AutWH"
      },
      "outputs": [],
      "source": [
        "\n",
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################\n",
        "\n",
        "y_pred_random = y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhIiQtyT8Le7"
      },
      "source": [
        "#Question 6\n",
        "\n",
        "##Predict the Majority Class\n",
        "\n",
        "To set the second baseline, add a model that predicts the majority class for the test data.\n",
        "\n",
        "Then, calculate and print the F1-score, Precision, and Recall in the form of a table. Finally, print the Macro F1-score across all of the classes as well.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bfVD_hVyFAN"
      },
      "outputs": [],
      "source": [
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################\n",
        "\n",
        "y_pred_majority = y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxApPTpoyVC3"
      },
      "source": [
        "##Now, let's move on to the model that we will be training in order to surpass the baseline.\n",
        "\n",
        "##Here, we're adding the parameters for the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b51_ePAl6MJ"
      },
      "outputs": [],
      "source": [
        "print(\"Creating parameters\")\n",
        "lr = 1e-3\n",
        "num_steps = 500\n",
        "batch_size = int(opts['batch_size'])\n",
        "n_batches = int(size/batch_size)\n",
        "\n",
        "print(\"Creating network parameters\")\n",
        "num_input = dim\n",
        "num_classes = nclass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bplMo4RlytL-"
      },
      "source": [
        "#Question 7\n",
        "\n",
        "##This function creates the model with the required weights and biases\n",
        "\n",
        "How would you add weights and biases for the 7 layers of neurons that we described earlier?\n",
        "\n",
        "Hint: Remember that you will need to add an extra layer - the output layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bMYvhaXriYh"
      },
      "outputs": [],
      "source": [
        "def bn_neural_net(x, dropout):\n",
        "  initializer = tf.keras.initializers.GlorotNormal()\n",
        "  weights = {\n",
        "      'h1': tf.Variable(initializer([num_input, n_hidden_1])),\n",
        "      'h2': tf.Variable(initializer([n_hidden_1, n_hidden_2])),\n",
        "      'h3': tf.Variable(initializer([n_hidden_2, n_hidden_3])),\n",
        "      'h4': tf.Variable(initializer([n_hidden_3, n_hidden_4])),\n",
        "      'h5': tf.Variable(initializer([n_hidden_4, n_hidden_5])),\n",
        "      'h6': tf.Variable(initializer([n_hidden_5, n_hidden_6])),\n",
        "      'h7': tf.Variable(initializer([n_hidden_6, n_hidden_7])),\n",
        "      'out': tf.Variable(initializer([n_hidden_7, num_classes]))\n",
        "  }\n",
        "\n",
        "  biases = {\n",
        "      'b1': tf.Variable(initializer([n_hidden_1])),\n",
        "      'b2': tf.Variable(initializer([n_hidden_2])),\n",
        "      'b3': tf.Variable(initializer([n_hidden_3])),\n",
        "      'b4': tf.Variable(initializer([n_hidden_4])),\n",
        "      'b5': tf.Variable(initializer([n_hidden_5])),\n",
        "      'b6': tf.Variable(initializer([n_hidden_6])),\n",
        "      'b7': tf.Variable(initializer([n_hidden_7])),\n",
        "      'out': tf.Variable(initializer([num_classes]))\n",
        "  }\n",
        "\n",
        "  def apply_layers(x, w, b, drop_rate):\n",
        "  ########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "  ############################################\n",
        "\n",
        "  x = apply_layers(x, weights['h1'], biases['b1'], dropout[0][0])\n",
        "  ########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "  ############################################\n",
        "\n",
        "  return out_layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcmmPcngr5O-"
      },
      "outputs": [],
      "source": [
        "def next_batch(num, data, labels):\n",
        "    num_el = data.shape[0]\n",
        "    while True:\n",
        "        idx = np.arange(0 , num_el)\n",
        "        np.random.shuffle(idx)\n",
        "        current_idx = 0\n",
        "        while current_idx < num_el:\n",
        "            batch_idx = idx[current_idx:current_idx+num]\n",
        "            current_idx += num\n",
        "            data_shuffle = [data[i,:] for i in batch_idx]\n",
        "            labels_shuffle = [labels[i] for i in batch_idx]\n",
        "            yield np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUnOKT2Vz4tp"
      },
      "source": [
        "#Question 8\n",
        "\n",
        "## Calculate batch loss and accuracy and print the details of the model\n",
        "\n",
        "Also, when the validation accuracy is better that the best validation accuracy previously achieved, we'd like to save the model. Otherwise, we'll be incrementing the value of the patience of the model.\n",
        "\n",
        "Attempt to add a condition for the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMZfsFfomxev"
      },
      "outputs": [],
      "source": [
        "def createTestModel(weightsValue=None):\n",
        "    print(\"Creating model\")\n",
        "    global_step = tf.Variable(0, trainable=False)\n",
        "\n",
        "    print(\"Graph input placeholders\")\n",
        "    X = tf.placeholder(\"float\", [None, num_input])\n",
        "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
        "    dropout = tf.placeholder(tf.float32, [5, 1])\n",
        "    out_layer = bn_neural_net(X, dropout)\n",
        "    prediction = tf.nn.softmax(out_layer)\n",
        "\n",
        "    # Use 'is None' instead of '== None'\n",
        "    if weightsValue is None:\n",
        "        weightsValue = Y\n",
        "\n",
        "    print(\"Creating class weights\")\n",
        "    class_weights = tf.constant([clw])\n",
        "    weights = tf.reduce_sum(class_weights * weightsValue, axis = 1)\n",
        "    unweighted_losses = tf.nn.softmax_cross_entropy_with_logits_v2(logits=out_layer, labels=Y)\n",
        "    weighted_losses = unweighted_losses * weights\n",
        "\n",
        "    loss_op = tf.reduce_mean(weighted_losses)\n",
        "\n",
        "    print(\"Evaluating model\")\n",
        "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "    lr = tf.train.exponential_decay(1e-2, global_step=global_step,decay_steps = 20000, decay_rate=0.5, staircase = True)\n",
        "    add_global = global_step.assign_add(1)\n",
        "\n",
        "    print(\"Optimizing\")\n",
        "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
        "    with tf.control_dependencies([add_global]):\n",
        "        train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "    saver = tf.train.Saver()\n",
        "    print(\"Initializing variables\")\n",
        "\n",
        "    best_acc = 0.0\n",
        "    train_acc = 0.0\n",
        "    pat = 0\n",
        "    list_train = []\n",
        "    list_test = []\n",
        "    drop = np.array([[0.5],[0.5],[0.5],[0.3],[0.2]], dtype=np.float32)\n",
        "    drop_0 = np.zeros((5,1), dtype=np.float32)\n",
        "    end = 0\n",
        "\n",
        "    with tf.Session(config=config) as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        print(sess.run(lr))\n",
        "        next_batch_gen = next_batch(int(batch_size), X_train, y_train)\n",
        "        for i in range(1, num_steps+1):\n",
        "            if end == 1:\n",
        "                break\n",
        "            for j in range(n_batches):\n",
        "                batch_x, batch_y = next(next_batch_gen)\n",
        "                sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, dropout: drop})\n",
        "                train_acc += sess.run(accuracy, feed_dict={X: batch_x, Y: batch_y, dropout: drop_0})\n",
        "                if j == n_batches-1:\n",
        "\n",
        "                    ########## TO BE ADDED BY STUDENT ##########\n",
        "                    # Calculate batch loss and accuracy.\n",
        "                    # Print the steps, loss, training & testing accuracy, and the learning rate\n",
        "\n",
        "\n",
        "                    # Add the condition described in the question\n",
        "                    ############################################\n",
        "\n",
        "                    if pat >= patience:\n",
        "                        print(\"Early Stop\")\n",
        "                        end = 1\n",
        "                        break\n",
        "\n",
        "        print(\"Testing Accuracy:\",sess.run(accuracy, feed_dict={X: X_test, Y: y_test, dropout: drop_0}))\n",
        "\n",
        "    # Restore and get predictions\n",
        "    with tf.Session(config=config) as sess:\n",
        "        saver.restore(sess, MODEL_PATH)\n",
        "        y_pred = sess.run(prediction, feed_dict={X: X_test, Y: y_test, dropout: drop_0})\n",
        "    return y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3QL6tvSLDV5"
      },
      "source": [
        "#Question 9\n",
        "\n",
        "## Now using the predicted and actual values, attempt to find the F1-score, Precision and Recall.\n",
        "\n",
        "\n",
        "Print the same in the form of a table that includes all of the classes and their respective scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZ_V_vwUkmr3"
      },
      "outputs": [],
      "source": [
        "def generate_evaluation_table(y_test, y_pred):\n",
        "  ########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "  ############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy5jXSLo4ge1"
      },
      "source": [
        "#Question 10\n",
        "\n",
        "##First, let's see what happens when the model is not optimized with the weights\n",
        "\n",
        "##Generate the table of F1, Precision, and Recall scores using the function defined previously"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lsvn_qLGFk82"
      },
      "outputs": [],
      "source": [
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################\n",
        "y_pred_no_weights = y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex5rzzzT4-G6"
      },
      "source": [
        "#Question 11\n",
        "##Now let us view the accuracy when it is trained with the help of the weights\n",
        "\n",
        "##Generate the table of F1, Precision, and Recall scores using the function defined previously"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qt7MIfZFn98"
      },
      "outputs": [],
      "source": [
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################\n",
        "y_pred_weights = y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI8LGDZODb_I"
      },
      "source": [
        "#Question 12\n",
        "\n",
        "##Now let us compare the results of all four models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCysYindxrnw"
      },
      "outputs": [],
      "source": [
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYlY89DJEOL7"
      },
      "source": [
        "\n",
        "\n",
        "##Let us create a table comparing only the F1-scores across each class and model\n",
        "\n",
        "Hint: This will be a variation of the generate_evaluation_table() function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn-L9vX5D_oQ"
      },
      "outputs": [],
      "source": [
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9exQ09rbGHmu"
      },
      "source": [
        "##Now visualize the results by plotting the F1-scores of each of these models. Let the X-axis be the classes and the Y-axis be the F1-scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AWW06pPx6a5"
      },
      "outputs": [],
      "source": [
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CKCgNzrUCLT"
      },
      "source": [
        "\n",
        "\n",
        "##Which class seems to be doing the best among the baseline models?\n",
        "\n",
        "Hint: Iterate through the training set and find the size of each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-5eRG70xt2f"
      },
      "outputs": [],
      "source": [
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBplsNFDWFSL"
      },
      "source": [
        "##Why is that class doing the best?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KexSmPcJVpCE"
      },
      "source": [
        "###Answer:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBTBJMJJKAjK"
      },
      "source": [
        "##Which class seems to be doing well across the models that are not a part of the baseline? Why do you think that is the case?\n",
        "\n",
        "Hint: Try mapping the importance of each of the features of the training set and each of the classes in the same in the form of a graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyfSn3UmYc5U"
      },
      "source": [
        "###Answer:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-MFf0eF4yL-"
      },
      "outputs": [],
      "source": [
        "########## TO BE ADDED BY STUDENT ##########\n",
        "\n",
        "\n",
        "############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUGKyqrPOaZs"
      },
      "source": [
        "#References\n",
        "\n",
        "1. Gerard Drapper Gil, Arash Habibi Lashkari, Mohammad Mamun, Ali A. Ghorbani, \"Characterization of Encrypted and VPN Traffic Using Time-Related Features\", In Proceedings of the 2nd International Conference on Information Systems Security and Privacy(ICISSP 2016) , pages 407-414, Rome, Italy. Dataset: https://www.unb.ca/cic/datasets/vpn.html\n",
        "\n",
        "2. “QA276390/encrypted_traffic_classification: Using deep learning to classify the encrypted network traffic,” GitHub. [Online]. Available: https://github.com/qa276390/Encrypted_Traffic_Classification.  \n",
        "\n",
        "3. https://machinelearningmastery.com/calculate-feature-importance-with-python/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}