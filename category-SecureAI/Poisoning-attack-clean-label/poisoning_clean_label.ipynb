{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inspire-lab/CyberAI-labs/blob/main/category-SecureAI/Poisoning-attack-clean-label/poisoning_clean_label.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfDZRuMgIrVB"
      },
      "source": [
        "# Poisoning Attacks part 2\n",
        "\n",
        "In this notebook we are running some attack specifically require a `KerasClassifier`. The `KerasClassifier` requires eager execution to be disabled. So one of the first things we are doing is to disable eager execution and importing most of the packages we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHH1CvFJIrVH"
      },
      "outputs": [],
      "source": [
        "!pip install adversarial-robustness-toolbox tensorflow==2.9.0\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "import numpy as np\n",
        "import art\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5rPTsi-IrVK"
      },
      "source": [
        "## Helper functions\n",
        "\n",
        "We need to redefine a couple of helper functions. These are identical to the functions\n",
        "used in part 1. These functions deal with model training, data loading, and image display."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cc8uqPJIrVL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# load the data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# normalize data\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "\n",
        "# convert image to the correct format\n",
        "if tf.keras.backend.image_data_format() == 'channels_first':\n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1],\n",
        "                            x_train.shape[2])\n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, x_train.shape[1],\n",
        "                          x_train.shape[2])\n",
        "else:\n",
        "  x_train = x_train.reshape(x_train.shape[0], x_train.shape[1],\n",
        "                            x_train.shape[2], 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], x_train.shape[1], x_train.shape[2],\n",
        "                          1)\n",
        "\n",
        "# a smaller version of the training data\n",
        "x_tr, y_tr = sklearn.utils.shuffle(x_train, y_train)\n",
        "x_tr = x_tr[:1000]\n",
        "y_tr = y_tr[:1000]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa7KM7v_IrVN"
      },
      "outputs": [],
      "source": [
        "def plot_grid(imgs, rows_cols=None, figsize=(15, 15), titles=None):\n",
        "    \"\"\"\n",
        "    Takes a list of images `imgs` and displays them in a grid with `n` rows and `m` columns.\n",
        "    To specify `n` and `m`, pass a tuple `(n, m)` as the `rows_cols` parameter.\n",
        "    `figsize` is forwarded to `matplotlib.pyplot.figure` as `figsize`.\n",
        "    `titles` can be used to set a title for each image in the grid. It should be a\n",
        "    list of `str` and must have the same number of elements as `imgs` if not None.\n",
        "    \"\"\"\n",
        "    num = imgs.shape[0]\n",
        "\n",
        "    # Calculate rows and columns\n",
        "    if rows_cols is None:\n",
        "        cols = int(np.sqrt(num))\n",
        "        rows = int(np.ceil(num / cols))  # Use np.ceil to ensure enough rows\n",
        "    else:\n",
        "        rows, cols = map(int, rows_cols)  # Ensure rows and cols are integers\n",
        "\n",
        "    # Create the figure\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "\n",
        "    # Plot each image in the grid\n",
        "    for i, img in enumerate(imgs):\n",
        "        ax = fig.add_subplot(rows, cols, i + 1)\n",
        "        if titles is not None:\n",
        "            ax.set_title(titles[i], fontsize=10)  # Add titles if provided\n",
        "        if len(img.shape) == 1:  # Handle flat grayscale images\n",
        "            img_size = int(np.sqrt(img.size))\n",
        "            plt.imshow(img.reshape(img_size, img_size), cmap=\"gray\")\n",
        "        elif len(img.shape) == 2:  # Grayscale image\n",
        "            plt.imshow(img, cmap=\"gray\")\n",
        "        else:  # RGB or multi-channel image\n",
        "            plt.imshow(img.squeeze())\n",
        "        plt.axis('off')  # Turn off axis labels\n",
        "\n",
        "    plt.tight_layout()  # Adjust spacing\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPAsqhaOIrVO"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras import models, layers, Input\n",
        "\n",
        "\n",
        "def get_cifar10_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(\n",
        "      layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n",
        "# Ensure eager execution\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "# Define the MNIST model\n",
        "def get_mnist_model(sparse_loss=True):\n",
        "    model = models.Sequential([\n",
        "        Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    if sparse_loss:\n",
        "        model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "    else:\n",
        "        model.compile(loss=\"categorical_crossentropy\",\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccd33d0f"
      },
      "outputs": [],
      "source": [
        "from art.attacks.poisoning import PoisoningAttackCleanLabelBackdoor, \\\n",
        "                                  PoisoningAttackBackdoor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02f08ebd"
      },
      "source": [
        "## Clean Label Attack\n",
        "\n",
        " The Clean label Attack relies on having a substitute classifier. To keep the\n",
        " labels clean the attack turns the poisoned instance into adversarial examples\n",
        " on the substitue classifier and relies on transferability of the adversarial\n",
        " examples to carry out the poisoning attack.\n",
        "\n",
        " For more details see the paper: https://people.csail.mit.edu/madry/lab/cleanlabel.pdf\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb1eaea1"
      },
      "source": [
        "## Q. Train a substitue classifier\n",
        "\n",
        "The substutie classifier should be called `art_classifier` and should be an `TensorFlowV2Classifier`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Reshape data to include the channel dimension\n",
        "if tf.keras.backend.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1], x_train.shape[2])\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1], x_test.shape[2])\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "\n",
        "# Create smaller training dataset\n",
        "x_tr, y_tr = sklearn.utils.shuffle(x_train, y_train)\n",
        "#x_tr = x_tr[:1000]\n",
        "#y_tr = y_tr[:1000]"
      ],
      "metadata": {
        "id": "bx4NIWEvFIde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4af700e7"
      },
      "outputs": [],
      "source": [
        "from art.estimators.classification import TensorFlowV2Classifier\n",
        "# you code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78f7f9f4"
      },
      "source": [
        "Using the substitue classifier we can create the Poisoning Attack, but first we\n",
        "need to choose a target class. Do so by changing the `target_class` variable\n",
        "below to a class of you choosing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d274a52"
      },
      "outputs": [],
      "source": [
        "target_class = 9 # could be any other class from 0-9\n",
        "if target_class == -1:\n",
        "  raise RuntimeError('need to choose a target class')\n",
        "target = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "target[target_class] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "585699b1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Create the backdoor pattern function\n",
        "def add_pattern_bd(x):\n",
        "    x_bd = np.copy(x)\n",
        "    for img in x_bd:\n",
        "        img[-3:, -3:, :] = 1  # Add a 3x3 white square in the bottom-right corner\n",
        "    return x_bd\n",
        "\n",
        "# Create the backdoor attack instance\n",
        "backdoor_attack = PoisoningAttackBackdoor(add_pattern_bd)\n",
        "\n",
        "\n",
        "clean_label_attack = PoisoningAttackCleanLabelBackdoor(\n",
        "    proxy_classifier=art_classifier,\n",
        "    backdoor=backdoor_attack,\n",
        "    norm=2,\n",
        "    eps=5,\n",
        "    eps_step=0.1,\n",
        "    max_iter=200,\n",
        "    target=target)\n",
        "\n",
        "# 3. create poison data\n",
        "poison, poison_labels = clean_label_attack.poison(x_tr, to_categorical(y_tr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48e09067"
      },
      "source": [
        "## Q. Display all instances of the target class and what class the substitute model classifies them as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a5a9ae0"
      },
      "outputs": [],
      "source": [
        "# code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "936ec590"
      },
      "source": [
        "Using the poisoned data we can train a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d13a1d8"
      },
      "outputs": [],
      "source": [
        "# train a model with the poisoned data\n",
        "victim_model = get_mnist_model()\n",
        "victim_model.fit(poison, np.argmax(poison_labels, axis=1), epochs=15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84384dbb"
      },
      "source": [
        "## Q. Evaluate the success of the attack.\n",
        "\n",
        "1. Show how the model performs on clean data\n",
        "2. Show how the model performs on posioned test data. (Be sure to only poison instance that are not the target class)\n",
        "3. Analyze if the poisoning is equally effective on all classes. If there is a discrepancy investigate the posioned training data to find out why.\n",
        "\n",
        "Bonus: Try to fix any issues in the poisoned training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quMeIMs0IrVY"
      },
      "outputs": [],
      "source": [
        "# you code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc7645e6"
      },
      "source": [
        "## Adversarial Embedding\n",
        "\n",
        "This attack trains a classifier with an additional discriminator and loss function that aims to create non-differentiable latent representations between backdoored and benign examples.\n",
        "\n",
        "First we are training the victim model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48bd31d4"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Normalize input data\n",
        "x_tr = x_tr / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Define the MNIST model\n",
        "def get_mnist_model(sparse_loss=False):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Input(shape=(28, 28, 1)),\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        keras.layers.Dropout(0.25),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    if sparse_loss:\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "             loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"]\n",
        "        )\n",
        "    else:\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"]\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "victim_model = get_mnist_model(sparse_loss=False)\n",
        "\n",
        "# Train the model\n",
        "victim_model.fit(x_tr, keras.utils.to_categorical(y_tr), epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "print('Model performance:',\n",
        "      victim_model.evaluate(x_test, keras.utils.to_categorical(y_test)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoI0y2NIIrVZ"
      },
      "source": [
        "Now we can setup the attack.\n",
        "\n",
        "You need to choose a `target_class`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06fIzCgEIrVZ"
      },
      "outputs": [],
      "source": [
        "from art.attacks.poisoning import PoisoningAttackBackdoor, \\\n",
        "                                  FeatureCollisionAttack, \\\n",
        "                                  PoisoningAttackAdversarialEmbedding\n",
        "from art.estimators.classification import KerasClassifier\n",
        "from art.attacks.poisoning.perturbations.image_perturbations import add_single_bd, \\\n",
        "                                                                    add_pattern_bd\n",
        "\n",
        "# define the image pertubation\n",
        "backdoor_attack = PoisoningAttackBackdoor(add_pattern_bd)\n",
        "\n",
        "# define the target class\n",
        "target_class = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RJ8xZ0LIrVZ"
      },
      "source": [
        "Setup the attack instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bd4451f"
      },
      "outputs": [],
      "source": [
        "# Disable eager execution\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# Wrap the model in ART's KerasClassifier\n",
        "art_victim_model = KerasClassifier(\n",
        "    model=victim_model,  # Pass the callable function\n",
        "    use_logits=False,           # Model outputs probabilities, not logits\n",
        "    clip_values=(0, 1)         # Normalize inputs between 0 and 1\n",
        ")\n",
        "\n",
        "# create a new attack instance\n",
        "adv_embedding = PoisoningAttackAdversarialEmbedding(\n",
        "    art_victim_model,\n",
        "    backdoor=backdoor_attack,\n",
        "    feature_layer=5,\n",
        "    target=keras.utils.to_categorical(target_class, num_classes=10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvfr_Ms1IrVa"
      },
      "source": [
        "Execute the attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b966bdbf"
      },
      "outputs": [],
      "source": [
        "poisoned_model = adv_embedding.poison_estimator(\n",
        "    x_tr, tf.keras.utils.to_categorical(y_tr), nb_epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0142FCjQIrVc"
      },
      "source": [
        "## Q. Evaluate the effectiveness of the poisoning attack\n",
        "\n",
        "Also investigate the examles that were used in the poisoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LfY631QIrVc"
      },
      "outputs": [],
      "source": [
        "# code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86bd18ec"
      },
      "source": [
        "## Feature Collision\n",
        "\n",
        "The goal here is that a specific target instance will be classified as a choosen target class. To achieve this we will poison a number of samples from the target class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7zmoCT9IrVd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "label_names = [\n",
        "    'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse',\n",
        "    'ship', 'truck'\n",
        "]\n",
        "\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "\n",
        "x_train, y_train = shuffle(x_train, y_train)\n",
        "\n",
        "# once again let's use a subset of the data to speed things up\n",
        "x_tr = x_train[:10000]\n",
        "y_tr = y_train[:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b32ce3d5"
      },
      "outputs": [],
      "source": [
        "sub_model = get_cifar10_model()\n",
        "sub_model.fit(x_tr, y_tr, epochs=15)\n",
        "sub_model.evaluate(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ccebbd6"
      },
      "outputs": [],
      "source": [
        "n_poison = 100  # number of instances to poison\n",
        "target_instance = x_test[y_test.squeeze() == 0][0]\n",
        "\n",
        "print('target instance')\n",
        "plt.imshow(target_instance.squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# get all images of the target class\n",
        "poision_instances = x_test[y_test.squeeze() == target_class]\n",
        "preds = np.argmax(sub_model.predict(poision_instances), axis=1)\n",
        "poision_instances = poision_instances[preds == target_class][:n_poison]\n",
        "predicictions = np.argmax(sub_model.predict(poision_instances), axis=1)\n",
        "print('data to be poisned')\n",
        "plot_grid(poision_instances, titles=[label_names[i] for i in predicictions])\n",
        "\n",
        "# create the actual poison data\n",
        "sub_wrapper = KerasClassifier(sub_model, clip_values=(0, 1))\n",
        "\n",
        "feature_collision_attack = FeatureCollisionAttack(\n",
        "    sub_wrapper,\n",
        "    target=target_instance[np.newaxis, :],\n",
        "    feature_layer=5,\n",
        "    max_iter=10,\n",
        "    similarity_coeff=1024.,\n",
        "    watermark=0.5)\n",
        "poison, y_poison = feature_collision_attack.poison(poision_instances,)\n",
        "# let's see what our poisned data looks like\n",
        "predicictions = np.argmax(sub_model.predict(poison), axis=1)\n",
        "print('poisoned instances')\n",
        "plot_grid(poison, titles=[label_names[i] for i in predicictions])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "363e3eb0"
      },
      "source": [
        "Time to poison a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYbnibYLIrVf"
      },
      "outputs": [],
      "source": [
        "y_poison.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89d09f62"
      },
      "outputs": [],
      "source": [
        "# combine the training data with the poisoned data\n",
        "x_poisoned = np.concatenate((x_tr, poison))\n",
        "y_poisoned = np.concatenate((y_tr, np.argmax(y_poison, axis=1)[:,np.newaxis]))\n",
        "victim_model = get_cifar10_model()\n",
        "victim_model.fit(x_poisoned, y_poisoned, epochs=15, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23f46c06"
      },
      "outputs": [],
      "source": [
        "#how do we perform on the clean test data\n",
        "print('clean data performance:', victim_model.evaluate(x_test, y_test))\n",
        "\n",
        "# let's try our target instance\n",
        "plt.imshow(target_instance.squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "print('prediction of the target instance',\n",
        "      np.argmax(victim_model.predict(target_instance[np.newaxis, :]), axis=1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "contrary-aspect"
      },
      "source": [
        "# Poisoning Attacks on Support Vector Machines (SVM) using Scikitlearn's SVC\n",
        "\n",
        "Here we will train an SVM that does spam detection. Then we will assume the role of a spammer and try weaken the the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceb4335a"
      },
      "outputs": [],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR490NP-IrVx"
      },
      "source": [
        "First we load the data into pandas dataframe https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
        "and display the first few instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "attached-reading"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import nltk\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from art.estimators.classification import SklearnClassifier\n",
        "from art.attacks.poisoning.poisoning_attack_svm import PoisoningAttackSVM\n",
        "\n",
        "# Correct reading of the CSV file\n",
        "data = pd.read_csv(\n",
        "    'data/SMSSpamCollection.csv',\n",
        "    encoding='latin-1',\n",
        "    sep=',',\n",
        "    header=0,  # No header in the CSV file\n",
        "    names=['class', 'text','empty1','empty2','empty3']  # Assign meaningful column names\n",
        ")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWgSsY05IrVy"
      },
      "source": [
        "Next we download the list of stopwords. Stopwords are the most common words in\n",
        "a language. Therfore they carry very little information and we can remove them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "civil-forest"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "# display list of stopwords for engish\n",
        "print(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "electrical-equation"
      },
      "source": [
        "#### Q. Write a function to filter out the stop words using and apply stemming\n",
        "\n",
        "\n",
        "The function `pre_process` takes in string and returns a string that contains the\n",
        "modified input.\n",
        "The following modifications need to be applied:\n",
        " - remove punctuation\n",
        " - remove stopwords\n",
        " - transform all words to lower case\n",
        " - stem all words, you can use the `stemmer` from the examples below.\n",
        " For more information on stemming check here: https://en.wikipedia.org/wiki/Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksa6yoLwIrV0"
      },
      "outputs": [],
      "source": [
        "# a few stemming examples\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "words = ['abnormal', 'excited', 'boring']\n",
        "for word in words:\n",
        "  print(word, stemmer.stem(word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3BP-LmIIrV0"
      },
      "outputs": [],
      "source": [
        "def pre_process(text):\n",
        "  # your code goes here\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "standing-professional"
      },
      "source": [
        "We'll use an `TfidfVectorizer` to turn our text feauters into numercial representation. But we will limit the amount of features it uses to 64, otherwise the attack takes a long time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hazardous-peace"
      },
      "outputs": [],
      "source": [
        "textFeatures = data['text']\n",
        "# check out what preporcessing does\n",
        "print('before preproccesing:', textFeatures[0])\n",
        "\n",
        "textFeatures = textFeatures.apply(pre_process)\n",
        "print('after preproccesing:', textFeatures[0])\n",
        "vectorizer = TfidfVectorizer(input=\"content\", max_features=64)\n",
        "features = vectorizer.fit_transform(textFeatures)\n",
        "\n",
        "# transform from sparse matrix nump array\n",
        "features = features.toarray()\n",
        "# transform from texutal labels to numerical\n",
        "labels = np.zeros((data['class'].shape[0],2))\n",
        "labels[data['class'] == 'ham'] = np.array([1,0])\n",
        "labels[data['class'] == 'spam'] = np.array([0,1])\n",
        "\n",
        "# split into training and test\n",
        "x_train, x_test, y_train, y_test = train_test_split(features,\n",
        "                                                    data['class'],\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=111)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6pqHBFeIrV1"
      },
      "source": [
        "To further reduce the time required to execute we will severly reduce the size of the training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "strong-specialist"
      },
      "outputs": [],
      "source": [
        "x_tr = x_train[0:20]\n",
        "y_tr = y_train[0:20]\n",
        "x_val = x_train[20:60]\n",
        "y_val = y_train[20:60]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYs33SZEIrV2"
      },
      "source": [
        "### Q. Write the attack function\n",
        "\n",
        "Complete the stub of the `get_attack_points` function below.\n",
        "The arguments of the functions are:\n",
        " - `x_train`: the training data 2D `ndarray`\n",
        " - `y_train`: categorical training labels 2D `ndarray`\n",
        " - `init_attack`: the instances to start the attack from 2D `ndarray`\n",
        " - `init_labels`: the labels used in the attack. should be different from the ground truth 2D `ndarray`\n",
        " - `x_val`: the validation data 2D `ndarray`\n",
        " - `y_val`: categorical validation labels 2D `ndarray`\n",
        " - `kernel`: the kernel used in the poisoned SVM `str`\n",
        "\n",
        "In the function train an `SVC` using `kernel` on `x_train` and `y_train`.\n",
        "Then create an instance of `PoisoningAttackSVM` and use that create a poisoned classifier and the attack points. Return both the attack points and the posioned classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R56FQo7NIrV2"
      },
      "outputs": [],
      "source": [
        "# soultion\n",
        "def get_attack_points(x_train, y_train, init_attack, init_labels, x_val, y_val, kernel):\n",
        "    # Create a SklearnClassifier with SVC\n",
        "    svc_model = SVC(kernel=kernel, probability=True)\n",
        "    poisoned_classifier = SklearnClassifier(model=svc_model, clip_values=(0, 1))\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    poisoned_classifier.fit(x_train, y_train)\n",
        "\n",
        "    # Print accuracy on validation set\n",
        "    print('accuracy unpoisoned on validation:',\n",
        "          poisoned_classifier.model.score(x_val, np.argmax(y_val, axis=1)))\n",
        "\n",
        "    # Create the poisoning attack\n",
        "    attack = PoisoningAttackSVM(\n",
        "        classifier=poisoned_classifier,  # Correct classifier type\n",
        "        step=0.5,\n",
        "        eps=10,\n",
        "        x_train=x_train,\n",
        "        y_train=y_train,\n",
        "        x_val=x_val,\n",
        "        y_val=y_val,\n",
        "        max_iter=100\n",
        "    )\n",
        "\n",
        "    # Generate the attack points\n",
        "    attack_point, _ = attack.poison(init_attack, y=init_labels)\n",
        "    return attack_point, poisoned_classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_train[20:] shape:\", y_train[20:].shape)"
      ],
      "metadata": {
        "id": "pW-Am-iQG2Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu5lMRMUIrV3"
      },
      "source": [
        "Using the `get_attack_points` function we can now execute the attack."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poG-MkfiIrV4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ensure y_tr and y_val are one-hot encoded\n",
        "num_classes = 2  # For \"ham\" and \"spam\"\n",
        "\n",
        "# Convert y_tr to one-hot encoding\n",
        "y_tr_one_hot = np.zeros((y_tr.shape[0], num_classes))\n",
        "y_tr_one_hot[y_tr == \"ham\"] = np.array([1, 0])\n",
        "y_tr_one_hot[y_tr == \"spam\"] = np.array([0, 1])\n",
        "\n",
        "# Convert y_val to one-hot encoding\n",
        "y_val_one_hot = np.zeros((y_val.shape[0], num_classes))\n",
        "y_val_one_hot[y_val == \"ham\"] = np.array([1, 0])\n",
        "y_val_one_hot[y_val == \"spam\"] = np.array([0, 1])\n",
        "\n",
        "\n",
        "kernel = 'linear'  # one of ['linear', 'poly', 'rbf']\n",
        "attack_point, poisoned = get_attack_points(\n",
        "    x_tr,               # Pass x_train as the first argument\n",
        "    y_tr_one_hot,       # Pass one-hot encoded y_train\n",
        "    init_attack,        # Initial attack point\n",
        "    np.array([[1, 0]]), # Target labels\n",
        "    x_val,              # Validation data\n",
        "    y_val_one_hot,      # Validation labels\n",
        "    kernel              # Kernel type\n",
        ")\n",
        "\n",
        "clean = SVC(kernel=kernel)\n",
        "art_clean = SklearnClassifier(clean, clip_values=(0, 1))\n",
        "art_clean.fit(x=x_tr, y=y_tr_one_hot)  # Use one-hot encoded labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform labels\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)  # Encodes ['ham', 'spam'] as [0, 1]\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "yQs1V78lGzJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku-5pqhWIrV5"
      },
      "source": [
        "### Q. Evaluate the success of the attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMP038swIrV5"
      },
      "outputs": [],
      "source": [
        "# you code goes here"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "404dd65280c70226f6403cbdbeb425cc0cfdb9f873eb0443d74906b6b826d0f5"
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}