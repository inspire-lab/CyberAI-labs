{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inspire-lab/CyberAI-labs/blob/main/category-SecureAI/Poisoning-attack-backdoor/poisoning_backdoor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "interracial-portsmouth",
      "metadata": {
        "id": "interracial-portsmouth"
      },
      "source": [
        "# Adversarial Machine learning: Poisoning attacks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beneficial-knife",
      "metadata": {
        "id": "beneficial-knife"
      },
      "source": [
        "So far with have been dealing with attacks that are launched against models that are already trained.\n",
        "In Poisoning attacks we are infiltrating the system earlier in the pipeline. Now we are attacking the model during training. For these attacks to succeed we need have influence over all of the training data or at least parts of the training data.\n",
        "\n",
        "<!-- In machine learning poisoning attacks, an attacker poison the model in order to change the learning outcome, by adding malicious data in the model training phase. This method can be performed, for example, by sending and injecting carefully designed samples when data collection is occuring during network operation, to train a network intrusion detection system model.  -->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "funded-terminal",
      "metadata": {
        "id": "funded-terminal"
      },
      "source": [
        "Poisoning attack come in two main types: The first type targets the machine learning system's availability. Whereasa the second one targets the integrity (also often called a backdoor attack).\n",
        "\n",
        "Availability attacks aim to inject so much of malicious data into an ML system that trained model becomes basically useless. Recent researchh shows that, even under strong defenses, a 3% poisoning in training dataset can lead to 11 % drop in accuracy of the model.\n",
        "\n",
        "Integrity or backdoor attacks are more sophisticated. They keep the classifier functionality exactly what it should be with one exception: a backdoor. A backdoor is a type of input that the modelâ€™s designer is not aware of, but that the attacker can leverage to get the ML system to do what they want. For example, imagine an attacker teaches a malware classifier that if a certain string is present in the file, that file should always be classified as benign. Now the attacker can compose any malware they want and as long as they insert that string into their file somewhere, they can make the model work as per his need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e52494",
      "metadata": {
        "id": "b0e52494"
      },
      "outputs": [],
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6063bb90",
      "metadata": {
        "id": "6063bb90"
      },
      "source": [
        "## Setup and Evalution functions\n",
        "\n",
        "We start out be importing all the modules we need, loading the data, and by\n",
        "defining some evaluation functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81d070f2",
      "metadata": {
        "id": "81d070f2"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import art\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f71f59c7",
      "metadata": {
        "id": "f71f59c7"
      },
      "source": [
        "Next we load the MNIST data set, normalize the data, and bring it into the\n",
        "format that tensorflow expects it in. Furthermore, to speed things up during\n",
        "training, we will select a smaller subsection of the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edfe45ca",
      "metadata": {
        "id": "edfe45ca"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# load the data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# normalize data\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "\n",
        "# convert image to the correct format\n",
        "if tf.keras.backend.image_data_format() == 'channels_first':\n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1],\n",
        "                            x_train.shape[2])\n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, x_train.shape[1],\n",
        "                          x_train.shape[2])\n",
        "else:\n",
        "  x_train = x_train.reshape(x_train.shape[0], x_train.shape[1],\n",
        "                            x_train.shape[2], 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], x_train.shape[1], x_train.shape[2],\n",
        "                          1)\n",
        "\n",
        "# a smaller version of the training data\n",
        "x_tr, y_tr = sklearn.utils.shuffle(x_train, y_train)\n",
        "x_tr = x_tr[:1000]\n",
        "y_tr = y_tr[:1000]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf0fc664",
      "metadata": {
        "id": "bf0fc664"
      },
      "source": [
        "Since we are working with images alot in this lab let's create function that\n",
        "displays multiple images in a grid layout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10e0f3bd",
      "metadata": {
        "id": "10e0f3bd"
      },
      "outputs": [],
      "source": [
        "def plot_grid(imgs, rows_cols=None, figsize=(15, 15), titles=None):\n",
        "    \"\"\"\n",
        "    Takes a list of images `imgs` and displays them in a grid. To specify\n",
        "    the number of rows and columns, pass a tuple `(n, m)` to the `rows_cols` parameter.\n",
        "    `figsize` is forwarded to `matplotlib.pyplot.figure` as `figsize`.\n",
        "    `titles` can be used to set a title for each image in the grid, which should be a\n",
        "    list of `str`. It needs to have the same number of elements as `imgs` if not None.\n",
        "    \"\"\"\n",
        "    num = imgs.shape[0]\n",
        "\n",
        "    # Determine the number of rows and columns if not specified\n",
        "    if rows_cols is None:\n",
        "        cols = int(np.sqrt(num))\n",
        "        if num % cols != 0:\n",
        "            cols += 1\n",
        "        rows = (num + cols - 1) // cols  # Ensure rows is an integer\n",
        "    else:\n",
        "        rows, cols = rows_cols\n",
        "\n",
        "    # Create the figure\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        ax = fig.add_subplot(rows, cols, i + 1)\n",
        "        if titles is not None:\n",
        "            ax.set_title(titles[i])\n",
        "\n",
        "        # Handle single-dimensional and multi-dimensional images\n",
        "        if len(img.shape) == 1:  # If the image is flattened\n",
        "            side = int(np.sqrt(img.size))\n",
        "            plt.imshow(img.reshape(side, side), cmap=\"gray\")\n",
        "        else:\n",
        "            plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd395ac0",
      "metadata": {
        "id": "cd395ac0"
      },
      "source": [
        "### Q. Use the `plot_grid` function to display 9 images from the training data. Each image should have it's label as title"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRR8lLSN_jZ4"
      },
      "id": "LRR8lLSN_jZ4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5586d5a5",
      "metadata": {
        "id": "5586d5a5"
      },
      "source": [
        "Next we are going to define functions that will create an untrained model for\n",
        "us. One for CIFAR-10 and one for MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fde07541",
      "metadata": {
        "id": "fde07541"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "def get_cifar10_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(\n",
        "      layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n",
        "def get_mnist_model(sparse_loss=True):\n",
        "  clf = models.Sequential()\n",
        "  clf.add(\n",
        "      layers.Conv2D(32,\n",
        "                    kernel_size=(3, 3),\n",
        "                    activation='relu',\n",
        "                    input_shape=(28, 28, 1)))\n",
        "  clf.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  clf.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  clf.add(layers.Dropout(0.25))\n",
        "  clf.add(layers.Flatten())\n",
        "  clf.add(layers.Dense(128, activation='relu'))\n",
        "  clf.add(layers.Dropout(0.5))\n",
        "  clf.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  if sparse_loss:\n",
        "    clf.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  else:\n",
        "    clf.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return clf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ed40f59",
      "metadata": {
        "id": "2ed40f59"
      },
      "source": [
        "# A very simple poisoning attack\n",
        "\n",
        "In the simplest form of poisoning we simply mislable parts of the training data.\n",
        "\n",
        "But first let's get a baseline by training the MNIST model for a few epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79e27220",
      "metadata": {
        "id": "79e27220"
      },
      "outputs": [],
      "source": [
        "# train a model on correctly labled data\n",
        "m = get_mnist_model()\n",
        "m.fit(x_tr, y_tr, epochs=5)\n",
        "print('clean model:', m.evaluate(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49cc7e22",
      "metadata": {
        "id": "49cc7e22"
      },
      "source": [
        "The performance isn't fantastic but remember that we are only using a small\n",
        "subset of the training data and are only train for a few epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e593030c",
      "metadata": {
        "id": "e593030c"
      },
      "source": [
        "### Q. Train a poisoned model. Poison the training data by changing the label of a precentage of the training data. Plot the the pefromance of the poisoned model on the test data for 10%, 25%, 33%, 50%, 66%, 75%, 90% and 100% of poisoned data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80a27f06",
      "metadata": {
        "id": "80a27f06"
      },
      "outputs": [],
      "source": [
        "# your code goes here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd91fd76",
      "metadata": {
        "id": "fd91fd76"
      },
      "source": [
        "How does the performance change if we increase or decrease the number of corrupted labels?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96fdd554",
      "metadata": {
        "id": "96fdd554"
      },
      "source": [
        "# More interessting poisoning attacks\n",
        "\n",
        "Confidence reduction is relativly simple todo. A more interessting scenario is to have model that performs nicely on clean data but has some hidden *trigger* that changes its behaviour. These backdoors allow us exploit behaviour of the model it would not normally display.\n",
        "\n",
        "Due to the poor explainability of neural networks, these backdoors are hard to detect in a trained model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9c1a466",
      "metadata": {
        "id": "c9c1a466"
      },
      "source": [
        "Let's start off by exploring some of the backdoor embedding functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c598ba",
      "metadata": {
        "id": "d9c598ba"
      },
      "outputs": [],
      "source": [
        "from art.attacks.poisoning.perturbations.image_perturbations import add_single_bd, \\\n",
        "                                                                    add_pattern_bd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e969e88",
      "metadata": {
        "id": "5e969e88"
      },
      "source": [
        "Let's load the CIFAR-10 data and normalize it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd09e684",
      "metadata": {
        "id": "fd09e684"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "(x_train_cf10, y_train_cf10), (x_test_cf10, y_test_cf10) = cifar10.load_data()\n",
        "\n",
        "x_train_cf10 = x_train_cf10 / 255.\n",
        "x_test_cf10 = x_test_cf10 / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da0ec4c2",
      "metadata": {
        "id": "da0ec4c2"
      },
      "source": [
        "Now that the data is loaded we can have a look at the data. To do so we display\n",
        "an image from the MNIST and one image from CIFAR-10 data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "427f1403",
      "metadata": {
        "id": "427f1403"
      },
      "outputs": [],
      "source": [
        "# pick a \"random\" sample\n",
        "x_mnist = x_train[42]\n",
        "x = x_train_cf10[42]\n",
        "\n",
        "plt.imshow(x_mnist.squeeze())\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(x)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1182ae24",
      "metadata": {
        "id": "1182ae24"
      },
      "outputs": [],
      "source": [
        "# add a simple backdoor\n",
        "x_p = add_single_bd(x_mnist.squeeze())\n",
        "plt.imshow(x_p.squeeze())\n",
        "plt.show()\n",
        "\n",
        "x_p = add_single_bd(x)\n",
        "plt.imshow(x_p)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c9d597c",
      "metadata": {
        "id": "8c9d597c"
      },
      "source": [
        "We can see that backdoor embedding does not work as intendend in color images."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59bfc440",
      "metadata": {
        "id": "59bfc440"
      },
      "source": [
        "### Q. Make an embedding function that does work for color images.\n",
        "\n",
        "The signature should be the same as the the function in ART\n",
        "\n",
        "```\n",
        "def add_single_bd(x: np.ndarray, distance: int = 2, pixel_value: int = 1) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Augments a matrix by setting value some `distance` away from the bottom-right edge to 1. Works for single images\n",
        "    or a batch of images.\n",
        "\n",
        "    :param x: N X W X H  matrix or W X H matrix\n",
        "    :param distance: Distance from bottom-right walls.\n",
        "    :param pixel_value: Value used to replace the entries of the image matrix.\n",
        "    :return: Backdoored image.\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "Fill in the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cca8eac7",
      "metadata": {
        "id": "cca8eac7"
      },
      "outputs": [],
      "source": [
        "def add_single_bd_rgb(x: np.ndarray,\n",
        "                      distance: int = 2,\n",
        "                      pixel_value: int = 1) -> np.ndarray:\n",
        "  \"\"\"\n",
        "  Augments a matrix by setting value some `distance` away from the bottom-right\n",
        "  edge to 1. Works for single images or a batch of images.\n",
        "\n",
        "  :param x: N X W X H matrix or W X H matrix\n",
        "  :param distance: Distance from bottom-right walls.\n",
        "  :param pixel_value: Value used to replace the entries of the image matrix.\n",
        "  :return: Backdoored image.\n",
        "  \"\"\"\n",
        "  x_modified = np.copy(x)\n",
        "  # add modifications\n",
        "  return x_modified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b69fd329",
      "metadata": {
        "id": "b69fd329"
      },
      "outputs": [],
      "source": [
        "# solution\n",
        "def add_single_bd_rgb(x: np.ndarray,\n",
        "                      distance: int = 2,\n",
        "                      pixel_value: int = 1) -> np.ndarray:\n",
        "  \"\"\"\n",
        "  Augments a matrix by setting value some `distance` away from the bottom-right\n",
        "  edge to 1. Works for single images or a batch of images.\n",
        "\n",
        "  :param x: N X W X H X C matrix or W X H X C matrix\n",
        "  :param distance: Distance from bottom-right walls.\n",
        "  :param pixel_value: Value used to replace the entries of the image matrix.\n",
        "  :return: Backdoored image.\n",
        "  \"\"\"\n",
        "  x_modified = np.copy(x)\n",
        "  if len(x.shape) == 4:  # batch of images\n",
        "    x_modified[:, -distance, -distance, :] = pixel_value\n",
        "  else:  #single image\n",
        "    x_modified[-distance, -distance, :] = pixel_value\n",
        "  return x_modified"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8fdfda7",
      "metadata": {
        "id": "f8fdfda7"
      },
      "source": [
        "Check that the new function works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96382c92",
      "metadata": {
        "id": "96382c92"
      },
      "outputs": [],
      "source": [
        "x_p = add_single_bd_rgb(x)\n",
        "plt.imshow(x_p)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68055e1e",
      "metadata": {
        "id": "68055e1e"
      },
      "source": [
        "Rather than just adding change a single pixle we can also add a pattern to the\n",
        "image. The pattern is going to be more obvious should someone inspect the iamge\n",
        "but it is also more robust."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c4e3b4",
      "metadata": {
        "id": "36c4e3b4"
      },
      "outputs": [],
      "source": [
        "# add a pattern backdoor\n",
        "x_p = add_pattern_bd(x_mnist.squeeze())\n",
        "plt.imshow(x_p)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d4bb1f0",
      "metadata": {
        "id": "1d4bb1f0"
      },
      "source": [
        "We can see the pattern in the bottom right of the image.\n",
        "\n",
        "But does it work with color images?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02022030",
      "metadata": {
        "id": "02022030"
      },
      "outputs": [],
      "source": [
        "# add a pattern backdoor\n",
        "x_p = add_pattern_bd(x.squeeze())\n",
        "plt.imshow(x_p)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceeaa54f",
      "metadata": {
        "id": "ceeaa54f"
      },
      "source": [
        "Once again it does not work for color images."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdeb03fd",
      "metadata": {
        "id": "cdeb03fd"
      },
      "source": [
        "### Q. Again make a function that does work for color images. It should work the same as the ART function and add the same pattern to the image.\n",
        "\n",
        "The signature should be the same as the the function in ART\n",
        "\n",
        "```\n",
        "def add_pattern_bd(x: np.ndarray, distance: int = 2, pixel_value: int = 1) -> np.ndarray:\n",
        "  ...\n",
        "```\n",
        "\n",
        "Fill in the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74f904e4",
      "metadata": {
        "id": "74f904e4"
      },
      "outputs": [],
      "source": [
        "def add_pattern_bd_rgb(x, distance=2, pixel_value=1):\n",
        "  x_modified = np.copy(x)\n",
        "  # add modifications\n",
        "  return x_modified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OfwVhCy-6Mc"
      },
      "source": [
        "Check that the new function works"
      ],
      "id": "0OfwVhCy-6Mc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96386c92",
      "metadata": {
        "id": "96386c92"
      },
      "outputs": [],
      "source": [
        "x_p = add_pattern_bd_rgb(x)\n",
        "plt.imshow(x_p)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1b819c2",
      "metadata": {
        "id": "f1b819c2"
      },
      "outputs": [],
      "source": [
        "# we can change the intensity and positioning\n",
        "x_p = add_pattern_bd(x_mnist.squeeze(), distance=5, pixel_value=.3)\n",
        "plt.imshow(x_p)\n",
        "plt.show()\n",
        "\n",
        "x_p = add_pattern_bd_rgb(x, distance=2, pixel_value=.3)\n",
        "plt.imshow(x_p)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5398fdc6",
      "metadata": {
        "id": "5398fdc6"
      },
      "source": [
        "### Q. At the moment the pattern method only supports embedding the pattern along the diagonal of the image. Create a function `add_pattern_bd_advanced` so that the `distance` argument can take a tuple. In the tuple `(x,y)`, x specifies the distance from the right border and y the distance from the left border. The function needs to support MNIST images, it does not need support color images. But it needs to support batches of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "754f1cf4",
      "metadata": {
        "id": "754f1cf4"
      },
      "outputs": [],
      "source": [
        "def add_pattern_bd_advanced(x, distance=2, pixel_value=1):\n",
        "  x_modified = np.copy( x )\n",
        "  if isinstance(distance, int):\n",
        "    # place image along thte diagonal\n",
        "    # add modifications\n",
        "  else:\n",
        "    # input was a tuple\n",
        "    # add modifications\n",
        "  return x_modified"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "414b458d",
      "metadata": {
        "id": "414b458d"
      },
      "source": [
        "Let's poison a MNIST model with a simple backdoor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2959b733",
      "metadata": {
        "id": "2959b733"
      },
      "source": [
        "We start by training a baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2682d239",
      "metadata": {
        "id": "2682d239"
      },
      "outputs": [],
      "source": [
        "mnist_baseline = get_mnist_model()\n",
        "\n",
        "mnist_baseline.fit(x_tr, y_tr, epochs=5)\n",
        "mnist_baseline.evaluate(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45bb3306",
      "metadata": {
        "id": "45bb3306"
      },
      "source": [
        "We want to poison a specfic class of the model. Our goal is to have the model\n",
        "predict a class, the `target_class`, of our choosing, when we add the marker.\n",
        "Let's assume we have controll over certain percentage `poison_precentage` of the\n",
        "training data. Meaning we can change the instances and labels at will. In the\n",
        "subset of the data we have control over we label add the marker to all instances\n",
        "that are not the target class and change their label to that of the target class."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "026c89da",
      "metadata": {
        "id": "026c89da"
      },
      "source": [
        "First we select a `target_class` and `poison_percentage`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b57cdce",
      "metadata": {
        "id": "7b57cdce"
      },
      "outputs": [],
      "source": [
        "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
        "# create the poisoned data set\n",
        "poison_precentage = .5\n",
        "target_class = 9\n",
        "\n",
        "# shuffel the data\n",
        "x_all, y_all = shuffle(x_tr, y_tr)\n",
        "\n",
        "# split the data into the part the we have controll over and the part we don't\n",
        "x_ours = x_all[:int(len(x_all) * poison_precentage)]\n",
        "y_ours = y_all[:int(len(y_all) * poison_precentage)]\n",
        "\n",
        "x_theirs = x_all[int(len(x_all) * poison_precentage):]\n",
        "y_theirs = y_all[int(len(y_all) * poison_precentage):]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "178adc53",
      "metadata": {
        "id": "178adc53"
      },
      "source": [
        "### Q. Create an ndarray `x_poison` that contains all instances from `x_ours` where the label is not `target_class` and an ndarray `poison_label` containing the `target_class` as label for each instance on `x_poison`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d062570b",
      "metadata": {
        "id": "d062570b"
      },
      "outputs": [],
      "source": [
        "# your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57843677",
      "metadata": {
        "id": "57843677"
      },
      "source": [
        "We now use the data you just created to poison the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c9fc67",
      "metadata": {
        "id": "75c9fc67"
      },
      "outputs": [],
      "source": [
        "# create attack instance\n",
        "backdoor_attack = PoisoningAttackBackdoor(add_pattern_bd)\n",
        "# add patern to instance\n",
        "poison, poison_labels = backdoor_attack.poison(x_poison, y=poison_labels)\n",
        "\n",
        "# combine our training data with the rest\n",
        "x_poison = np.concatenate([x_theirs, poison])\n",
        "y_poison = np.concatenate([y_theirs, poison_labels])\n",
        "\n",
        "# shuffel the data\n",
        "x_poison, y_poison = shuffle(x_poison, y_poison)\n",
        "plot_grid(poison[:64])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f44da4e",
      "metadata": {
        "id": "2f44da4e"
      },
      "source": [
        "We can now use the poisoned data train model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66f2b618",
      "metadata": {
        "id": "66f2b618"
      },
      "outputs": [],
      "source": [
        "# train a model on poisoned data\n",
        "poisoned_model = get_mnist_model()\n",
        "poisoned_model.fit(x_poison, y_poison, epochs=5)\n",
        "# performance on clean data\n",
        "poisoned_model.evaluate(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbb3c533",
      "metadata": {
        "id": "fbb3c533"
      },
      "source": [
        "### Q. Evaluate the success of the attack.\n",
        "\n",
        "To show the attack was successful we need to show 2 things.\n",
        "1. Show that the model performs well on data that does not contain the marker\n",
        "2. Show that the model predicts the target class when add ther marker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3ba5fae",
      "metadata": {
        "id": "f3ba5fae"
      },
      "outputs": [],
      "source": [
        "# evalution goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36bafd09",
      "metadata": {
        "id": "36bafd09"
      },
      "source": [
        "### Q. Evaluate embedding strategies.\n",
        "\n",
        "There are number of things you need to compare.\n",
        "\n",
        "1. Compare the impact of the `poison_percentage`. Plot the evaluation for 0.1, 0.25, 0.33, and 0.5.\n",
        "2. Compare the effectiveness of using a pattern against just using a single pixel as a marker. Use the same `poison_percentage` as above.\n",
        "3. When using a pattern compare the effectiveness of different marker placement. Compare the following marker placements: bottom right, center, and random. Use the same `poison_percentage` as above.\n",
        "4. Using a pattern compare the impact of the `pixel_value`. Compare values 0.01, 0.25, 0.5, 0.75, and 1.0. Use the same `poison_percentage` use the pattern placement you found to be most successful in the previous experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "368eebec",
      "metadata": {
        "id": "368eebec"
      },
      "outputs": [],
      "source": [
        "#evaluation goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd84c472",
      "metadata": {
        "id": "bd84c472"
      },
      "source": [
        "The downside of the attacks that we have used so far have the major downside that labels aren't clean. Most of our poisoned data is clearly labled incorrectly.\n",
        "\n",
        "Let's adress this issue with clean label attacks. Which can be found in part 2."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}